{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    "- The structure of the code is given to you and you will need to fill in the parts corresponding to each question. \n",
    "- You will have to submit the completed notebook in the Jupyter notebook format: `.ipynb`.\n",
    "- Do not modify/erase other parts of the code if you have not been given specific instructions to do so.\n",
    "- When you are asked to insert code, do so between the areas which begin:\n",
    "  \n",
    "  `##########################################################`\n",
    "  \n",
    "  `# TO_DO`\n",
    "  \n",
    "  `#[your code here]`\n",
    "   \n",
    "   And which end:\n",
    "   \n",
    "  `# /TO_DO\n",
    "   ##########################################################`\n",
    "\n",
    "\n",
    "- When you are asked to comment on the results you should give clear and comprehensible explanations. Write the comments in a 'Code Cell' with a sign `#` at the beginning of each row, and in the areas which begin:\n",
    "\n",
    "  `# [INSERT YOUR ANSWER HERE]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Please do not change the cell below, you will see a number of imports. All these packages are relevant for the assignment and it is important that you get used to them. You can find more information about them in their respective documentation. The most relevant package for this assignment is Scikit-learn:\n",
    "\n",
    "https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLEASE DO NOT CHANGE THIS CELL\n",
    "\n",
    "# Standard python libraries for data and visualisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# SciKit Learn python ML Library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "\n",
    "# Import error metric\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Import library for handling warnings\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLEASE DO NOT CHANGE THIS CELL\n",
    "\n",
    "# Functions to use\n",
    "# Decision boundary plotting \n",
    "def plot_predictions(X, y, clf):\n",
    "    h = .02  # step size in the mesh\n",
    " \n",
    "    # create a mesh to plot in\n",
    "    x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\n",
    "    y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "\n",
    "    # Plot also the training points\n",
    "    pylab.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "    plt.xlabel(list(X.head(0))[0])\n",
    "    plt.ylabel(list(X.head(0))[1])\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(np.arange(min(X.iloc[:, 0]), max(X.iloc[:, 0])+1, 1.0))\n",
    "    plt.yticks(np.arange(min(X.iloc[:, 1]), max(X.iloc[:, 1])+1, 1.0))\n",
    "    plt.title(clf)\n",
    "\n",
    "    plt.show\n",
    "    \n",
    "# confusion matrix plotting plotting\n",
    "def plot_conf_matrix(conf_matrix):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\" ,fmt='g')    \n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Logistic Regression [50 marks]\n",
    "\n",
    "## Seeds dataset\n",
    "This dataset contains gene expression data from patients diagnosed with one of tumor types: BRCA, KIRC, COAD, LUAD and PRAD. Each feature corresponds to a different gene. \n",
    "\n",
    "Dataset location: https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq\n",
    "\n",
    "Number of instances: 801\n",
    "\n",
    "Number of features: 20531   \n",
    "\n",
    "All of these parameters are real-valued continuous. To reduce computation time, we are going to work with the first 200 features.\n",
    "\n",
    "## Load dataset\n",
    "Please save the 'data.csv' and 'labels.csv' files included in the assignement zip file, which contain this data, and change the paths below to the paths leading to the location of your downloaded files. You may want to use os.chdir to change directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PLEASE CHANGE THE FILE PATHS \n",
    "\n",
    "file_path_data = \"yourFilePath/data.csv\"\n",
    "file_path_labels = \"yourFilePath/labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLEASE DO NOT CHANGE THIS CELL\n",
    "\n",
    "# read the file with pandas.read_csv\n",
    "X = pd.read_csv(file_path_data, usecols=[*range(1, 200)])\n",
    "y = pd.read_csv(file_path_labels, usecols=[1]).values.ravel()\n",
    "\n",
    "label_list = [\"BRCA\", \"KIRC\", \"COAD\", \"LUAD\", \"PRAD\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis and pre-processing \n",
    "Below, we will generate histograms of the first 12 'Gene expression cancer RNA-Seq' dataset features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLEASE DO NOT CHANGE THIS CELL\n",
    "\n",
    "figs, axs = plt.subplots(3, 4, figsize=(12, 10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for counter in range(12):\n",
    "    col = X.columns[counter]\n",
    "    axs[counter].hist(X[col], bins=20)\n",
    "    axs[counter].set_title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularisation makes the classifier dependent on the scale of the features. \n",
    "\n",
    "We are going to scale the features and compare the performance of Logistic Regression on unscaled and scaled dataset. \n",
    "\n",
    "### _Question 1 [10 marks]_ \n",
    "\n",
    "### _a) [3 marks]_ \n",
    "- Use `StandardScaler()` to scale the data. Save the result to a new variable (do not overwrite X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _b) [3 marks]_\n",
    "-  Explain how the `StandardScaler()` function changes the data, (in particular its mean and variance)? (**Hint:** You can re-run the code from the section **Data analysis and pre-processing** in order to visualise scaled values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [INSERT YOUR ANSWER HERE]\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _c) [4 marks]_\n",
    "- `LogisticRegression()` uses $\\ell_2$ regularisation as default. Briefly explain the effect of such a regulariser. Furthermore, briefly explain why data scaling might be a useful pre-processing step before the application of such a regulariser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [INSERT YOUR ANSWER HERE]\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Confusion Matrix is a table used for the evaluation of classification models. The x axis represents predicted labels while the y axis represents actual labels. Each cell indicates the sum of instances assigned to a particular combination of these labels. Diagonal values represents correctly classified instances.  \n",
    "\n",
    "### _Question 2 [20 marks]_\n",
    "\n",
    "### _a) [5 marks]_ \n",
    "- Create training and testing datasets for the unscaled and scaled data (set `random_state=42` when making your split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression(solver = \"lbfgs\", multi_class = \"multinomial\", max_iter = 5000)\n",
    "lg_scaled = LogisticRegression(solver = \"lbfgs\", multi_class = \"multinomial\", max_iter = 5000)\n",
    "\n",
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _b) [5 marks]_ \n",
    "- Fit `LogisticRegression()` to the unscaled and scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _c) [5 marks]_ \n",
    "- Print confusion matrices for the scaled and unscaled data using Scikit-learn `confusion_matrix()` functon defined for you at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _d) [5 marks]_ \n",
    "- Print a classification report using scikit-learn `classification_report()` function. You can use `target_names = label_list` to include labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "In Scikit-learn, `StratifiedKFold()` splits the data into $k$ different folds.  \n",
    "`cross_val_score()` then uses these folds to run the classifier multiple times and collect multiple accuracy scores.   \n",
    "\n",
    "### _Question 3 [20 marks]_\n",
    "\n",
    "### _a) [5 marks]_ \n",
    "- Split data using `StratifiedKFold()`. Set `n_splits = 10`, `shuffle = True`, and `random_state=42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # please note the lines above are used to silence sklearn warnings\n",
    "    # which is not necessary\n",
    "    \n",
    "    #######################################################\n",
    "    # TO_DO\n",
    "    #[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #/TO_DO\n",
    "    ########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _b) [5 marks]_ \n",
    "- Calculate cross validation scores using `cross_val_score()`. Call the variables storing these scores `lg_scores` and `lg_scaled_scores` (for consistency with plotting done for you in the subsequent section). (**Hint:** `cv` is equal to the output of `StratifiedKFold()`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # please note the lines above are used to silence sklearn warnings\n",
    "    # which is not necessary\n",
    "\n",
    "    #######################################################\n",
    "    # TO_DO\n",
    "    #[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #/TO_DO\n",
    "    ########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _c) [5 marks]_ \n",
    "- Calculate and print the mean of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # please note the lines above are used to silence sklearn warnings\n",
    "    # which is not necessary\n",
    "\n",
    "    #######################################################\n",
    "    # TO_DO\n",
    "    #[your code here]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #/TO_DO\n",
    "    ########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _d) [5 marks]_ \n",
    "- Unlike vanilla `KFold()`, `StratifiedKFold()` aims to preserve the proportion of examples belonging to each class in each split. Does `StratifiedKFold()` make each data split balanced if the whole dataset is not balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [INSERT YOUR ANSWER HERE]\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise the scores using a box plot. It highlights the lower and upper quartiles, and \"whiskers\" showing the extent of the scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLEASE DO NOT CHANGE THIS CELL\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot([1]*10, lg_scores, \".\")\n",
    "plt.plot([2]*10, lg_scaled_scores, \".\")\n",
    "plt.boxplot([lg_scores, lg_scaled_scores], labels=(\"logistic regression\",\"logistic regression w/ scaling\"))\n",
    "plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Naive Bayes [50 marks]\n",
    "\n",
    "Please note that we are still working with the 'Gene expression cancer RNA-Seq' dataset loaded in Part A.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing correlated features\n",
    "Feature independence is an assumption of Naive Bayes. Naive Bayes is particularly sensitive to feature correlations which can lead to overfitting. Based on data alone, we cannot test if features are truly independent, but we can exclude correlated features.\n",
    "Below, we test if features are correlated.\n",
    "\n",
    "### _Question 4 [10 marks]_\n",
    "Drop features with correlation above 0.75. \n",
    "\n",
    "**Hint:** see what `to_drop` returns, then use it as an argument in the *pandas* `drop()` function with `axis = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.75\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "\n",
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "#######################################################\n",
    "\n",
    "print(\"Correlated features dropped: \")\n",
    "print(*to_drop, sep = \", \") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Recursive feature elimination\n",
    "Lets go further and select the 5 most important features. Recursive Feature Elimination (RFE) is designed to select features by recursively considering smaller and smaller sets of features.  \n",
    "\n",
    "### _Question 5 [10 marks]_\n",
    "\n",
    "### _a) [5 marks]_ \n",
    "- Use the `RFE()` function in Scikit-learn to select features. (**Hint:** Check the Scikit-learn documentation and example.)\n",
    "\n",
    "### _b) [5 marks]_ \n",
    "- After selecting features to eliminate, use the `support_` attribute as a mask to select the right columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "#######################################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "nb.fit(X_train, y_train)\n",
    "nb_predict = nb.predict(X_test)\n",
    "print(classification_report(y_test, nb_predict, target_names = label_list))\n",
    "nb_confusion = confusion_matrix(y_test, nb_predict)\n",
    "plot_conf_matrix(nb_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to switch to a different dataset.\n",
    "### Zoo dataset \n",
    "This is a simple dataset which classifies animals into 7 categories. \n",
    "\n",
    "Dataset location: https://archive.ics.uci.edu/ml/datasets/Zoo  \n",
    "\n",
    "Number of instances: 210\n",
    "\n",
    "Number of features: 17\n",
    "\n",
    "Attribute Information:  \n",
    "1. animal name: Unique for each instance   \n",
    "2. hair:\tBoolean   \n",
    "3. feathers:\tBoolean   \n",
    "4. eggs:\tBoolean   \n",
    "5. milk:\tBoolean   \n",
    "6. airborne:\tBoolean   \n",
    "7. aquatic:\tBoolean   \n",
    "8. predator:\tBoolean   \n",
    "9. toothed:\tBoolean   \n",
    "10. backbone:\tBoolean   \n",
    "11. breathes:\tBoolean   \n",
    "12. venomous:\tBoolean   \n",
    "13. fins:\tBoolean   \n",
    "14. legs:\tNumeric (set of values: {0,2,4,5,6,8})   \n",
    "15. tail:\tBoolean   \n",
    "16. domestic:\tBoolean   \n",
    "17. catsize:\tBoolean   \n",
    "18. type:\tNumeric (integer values in range [1,7])  \n",
    "\n",
    "All of these parameters are discrete-valued.\n",
    "  \n",
    "### Load dataset\n",
    "Please save the 'zoo.csv' file included in the assignement zip file, which contains a subset of this data, and change the paths below to the paths leading  to the location of your downloaded files. You may want to use `os.chdir` to change directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PLEASE CHANGE THE FILE PATHS \n",
    "\n",
    "file_path_data_zoo = \"yourFilePath/zoo.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLEASE DO NOT CHANGE THIS CELL\n",
    "\n",
    "# read the file with pandas.read_csv\n",
    "data_zoo = pd.read_csv(file_path_data_zoo)\n",
    "\n",
    "# because the file does not contain header information, we manually add headers of the dataset\n",
    "data_zoo.columns = [\"animal name\", \"hair\", \"feathers\",\"eggs\", \n",
    "                \"milk\", \"airborne\",\"aquatic\", \"predator\", \"toothed\", \"backbone\", \n",
    "                    \"breathless\", \"venomous\", \"fins\", \"legs\", \"tail\", \"domestic\", \"catsize\", \"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign columns 2 to 18 (everything other than animal name and class) to variable `X_zoo`. Remember that indexing starts at 0.  \n",
    "We assign the \"class\" column to variable `y`.  \n",
    "We then split `X` and `y` into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLEASE DO NOT CHANGE THIS CELL\n",
    "\n",
    "X_zoo = data_zoo.iloc[:,1:17]\n",
    "y_zoo = data_zoo[\"class\"]\n",
    "X_zoo_train, X_zoo_test, y_zoo_train, y_zoo_test = train_test_split(X_zoo, y_zoo, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a test dataset which contains only animals with 4 or fewer legs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLEASE DO NOT CHANGE THIS CELL\n",
    "\n",
    "X_drop_train = X_zoo_train.drop(X_zoo_train[X_zoo_train[\"legs\"]>4].index)\n",
    "y_drop_train = y_zoo_train.drop(X_zoo_train[X_zoo_train[\"legs\"]>4].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of a multinomial Naive Bayes classifier. We train `nb` on `X_drop_train`, and test it on `X_zoo_test`.  \n",
    "You should get an error message suggesting that the value of alpha is automatically overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLEASE DO NOT CHANGE THIS CELL\n",
    "\n",
    "nb = MultinomialNB(alpha =0)\n",
    "nb.fit(X_drop_train, y_drop_train)\n",
    "nb_predict_train = nb.predict(X_drop_train)\n",
    "nb_predict_test = nb.predict(X_zoo_test)\n",
    "print(accuracy_score(nb_predict_train, y_drop_train))\n",
    "print(accuracy_score(nb_predict_test, y_zoo_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Question 6 [10 marks]_   \n",
    "Please comment on what the alpha parameter does.\n",
    "**Hints:**  \n",
    "- Think what Naive Bayes does when encountering a discrete feature value of which is absent in the train dataset but which is present in the test dataset. What probability estimate would be associated with it?  \n",
    "- See: Scikit-learn `MultinomialNB` documentation, in particular the description of the alpha parameter https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### [INSERT YOUR ANSWER HERE]\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going  to repeat the above process using Naive Bayes for features with the Bernoulli distribution (`BernoulliNB()` in scikit-learn). We are particularly interested in interpreting decision boundaries of Bernoulli Naive Bayes.\n",
    "\n",
    "### _Question 7 [20 marks]_\n",
    "\n",
    "### _a) [2 marks]_ \n",
    "- Use recursive feature elimination (RFE) is to select only 2 features (**Note:** in real life cases, you are likely to use this approach to select multiple rather than just two features. In this case we are asking you to analyse the outcome, and 2 features allows us to visualise the decision boundary more easily.)\n",
    "\n",
    "### _b) [1 mark]_ \n",
    "- After selecting the features to eliminate, use the `support_` attribute as a mask to select the right columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = BernoulliNB()\n",
    "\n",
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _c) [2 marks]_ \n",
    "- Split data into train and test sets (set `random_state=42`).\n",
    "\n",
    "### _d) [1 mark]_ \n",
    "- Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _e) [2 marks]_ \n",
    "- Create a Confusion Matrix using the `plot_conf_matrix()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _f) [2 marks]_ \n",
    "- Plot decision boundaries using the `plot_predictions()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TO_DO\n",
    "#[your code here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#/TO_DO\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _g) [10 marks]_ \n",
    "- Interpret the decision boundaries: Recall the shapes of decision boundaries you have seen in classes - were they straight and crossing at right angles? Why is this the case when using `BernoulliNB()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### [INSERT YOUR ANSWER HERE]\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
